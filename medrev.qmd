---
title: "MedScrape: AI-Powered Literature Review Platform"
subtitle: "Automated Research Gap Identification Through Intelligent Clustering"
page-layout: full
---

## Overview

MedScrape is an advanced literature review platform that leverages natural language processing and machine learning to automate the tedious process of conducting systematic literature reviews. It scrapes PubMed, clusters research articles using multiple unsupervised learning algorithms, and identifies research gaps by comparing review papers against primary research.

**Repository:** [github.com/lonespear/medrev](https://github.com/lonespear/medrev)

**Live Demo:** [medreview.streamlit.app](https://medreview.streamlit.app/)

**Research Paper:** "Literature Reviews in the Age of Precision Nutrition"

---

## Key Features

### 1. Automated PubMed Database Scraping

Seamlessly interfaces with the NCBI Entrez API to retrieve research articles:

- **Advanced Query Builder**: Boolean operators (AND, OR, NOT) with nested queries
- **Date Range Filtering**: Target specific publication periods
- **Publication Type Filtering**: Separate reviews from research articles
- **Custom CSV Upload**: Analyze your own literature collections
- **Automatic Article Classification**: Identifies review vs. research papers

```python
# Example PubMed query construction
def search_pubmed(query, start_date, end_date, max_results=1000):
    """
    Search PubMed with advanced filtering

    Parameters:
    -----------
    query : str
        Search terms with boolean operators
        Example: '("genetics" OR "GWAS") AND ("nutrition" OR "diet")'
    start_date : str
        Start date (YYYY/MM/DD)
    end_date : str
        End date (YYYY/MM/DD)
    max_results : int
        Maximum articles to retrieve

    Returns:
    --------
    articles : list
        List of article dictionaries with metadata
    """
    from Bio import Entrez

    Entrez.email = "your.email@example.com"

    # Construct date-filtered query
    date_filter = f"{start_date}:{end_date}[PDAT]"
    full_query = f"({query}) AND ({date_filter})"

    # Search PubMed
    handle = Entrez.esearch(
        db="pubmed",
        term=full_query,
        retmax=max_results,
        sort="relevance"
    )
    record = Entrez.read(handle)
    pmids = record["IdList"]

    # Fetch article details
    handle = Entrez.efetch(
        db="pubmed",
        id=pmids,
        rettype="medline",
        retmode="text"
    )

    # Parse results
    articles = parse_medline_records(handle)

    return articles
```

### 2. Multiple Clustering Algorithms

Employs diverse unsupervised learning techniques to discover thematic patterns:

#### K-Means Clustering
- **Best For**: Clear, well-separated topics
- **Advantages**: Fast, deterministic, interpretable
- **Use Case**: Initial exploration, known number of topics

```python
from sklearn.cluster import KMeans

# K-Means clustering
kmeans = KMeans(
    n_clusters=8,
    init='k-means++',
    n_init=10,
    max_iter=300,
    random_state=42
)
cluster_labels = kmeans.fit_predict(document_vectors)
```

#### DBSCAN (Density-Based Spatial Clustering)
- **Best For**: Irregular cluster shapes, outlier detection
- **Advantages**: No predefined cluster count, noise robust
- **Use Case**: Discovering organic topic structures

```python
from sklearn.cluster import DBSCAN

# DBSCAN clustering
dbscan = DBSCAN(
    eps=0.5,            # Maximum distance between points
    min_samples=5,      # Minimum cluster size
    metric='cosine'     # Similarity metric
)
cluster_labels = dbscan.fit_predict(document_vectors)
```

#### Hierarchical Clustering
- **Best For**: Taxonomic relationships, nested topics
- **Advantages**: Creates dendrogram, multi-scale analysis
- **Use Case**: Understanding topic hierarchies

```python
from sklearn.cluster import AgglomerativeClustering

# Hierarchical clustering
hierarchical = AgglomerativeClustering(
    n_clusters=8,
    linkage='ward',     # Minimizes variance
    affinity='euclidean'
)
cluster_labels = hierarchical.fit_predict(document_vectors)
```

#### LDA (Latent Dirichlet Allocation)
- **Best For**: Topic modeling, document-topic distributions
- **Advantages**: Probabilistic, interpretable topics
- **Use Case**: Understanding document composition

```python
from sklearn.decomposition import LatentDirichletAllocation

# LDA topic modeling
lda = LatentDirichletAllocation(
    n_components=8,
    max_iter=10,
    learning_method='online',
    random_state=42
)
topic_distributions = lda.fit_transform(document_term_matrix)
```

### 3. Flexible Embedding Methods

Three approaches to convert documents into numerical vectors:

#### TF-IDF (Term Frequency-Inverse Document Frequency)
- **Speed**: Fastest
- **Memory**: Minimal
- **Best For**: Large corpora, quick analysis

```python
from sklearn.feature_extraction.text import TfidfVectorizer

tfidf = TfidfVectorizer(
    max_features=5000,
    min_df=2,
    max_df=0.8,
    ngram_range=(1, 2),
    stop_words='english'
)
vectors = tfidf.fit_transform(abstracts)
```

#### Doc2Vec
- **Speed**: Moderate
- **Memory**: Moderate
- **Best For**: Context-aware representations

```python
from gensim.models.doc2vec import Doc2Vec, TaggedDocument

# Prepare documents
tagged_docs = [TaggedDocument(words=doc.split(), tags=[str(i)])
               for i, doc in enumerate(abstracts)]

# Train Doc2Vec model
model = Doc2Vec(
    tagged_docs,
    vector_size=100,
    window=5,
    min_count=2,
    epochs=40,
    dm=1  # Distributed memory
)

# Get document vectors
vectors = [model.dv[str(i)] for i in range(len(abstracts))]
```

#### FastText
- **Speed**: Slower
- **Memory**: Higher
- **Best For**: Robust to typos, rare words

```python
from gensim.models.fasttext import FastText

# Train FastText model
sentences = [doc.split() for doc in abstracts]
model = FastText(
    sentences,
    vector_size=100,
    window=5,
    min_count=2,
    epochs=10,
    word_ngrams=1
)

# Average word vectors for document representation
vectors = []
for doc in sentences:
    doc_vector = np.mean([model.wv[word] for word in doc
                          if word in model.wv], axis=0)
    vectors.append(doc_vector)
```

### 4. Dimensionality Reduction

Reduces high-dimensional embeddings for visualization and analysis:

#### PCA (Principal Component Analysis)
- **Type**: Linear
- **Speed**: Fastest
- **Best For**: Initial exploration

```python
from sklearn.decomposition import PCA

pca = PCA(n_components=3)
reduced = pca.fit_transform(vectors)
```

#### t-SNE (t-Distributed Stochastic Neighbor Embedding)
- **Type**: Non-linear
- **Speed**: Moderate
- **Best For**: Detailed cluster visualization

```python
from sklearn.manifold import TSNE

tsne = TSNE(
    n_components=3,
    perplexity=30,
    n_iter=1000,
    random_state=42
)
reduced = tsne.fit_transform(vectors)
```

#### UMAP (Uniform Manifold Approximation and Projection)
- **Type**: Non-linear
- **Speed**: Fast
- **Best For**: Best balance of speed and quality

```python
import umap

reducer = umap.UMAP(
    n_components=3,
    n_neighbors=15,
    min_dist=0.1,
    metric='cosine'
)
reduced = reducer.fit_transform(vectors)
```

### 5. Research Gap Identification

**Novel Feature**: Compares review papers against primary research to find underexplored areas.

#### Algorithm

```python
def identify_research_gaps(review_clusters, research_clusters, threshold=0.3):
    """
    Identify research gaps by comparing review and research clusters

    Parameters:
    -----------
    review_clusters : dict
        {cluster_id: [review_article_indices]}
    research_clusters : dict
        {cluster_id: [research_article_indices]}
    threshold : float
        Minimum similarity to consider coverage

    Returns:
    --------
    gaps : dict
        {research_cluster_id: coverage_metrics}
    """
    # Extract cluster centroids
    review_centroids = compute_centroids(review_clusters)
    research_centroids = compute_centroids(research_clusters)

    # Compute similarity matrix
    similarity_matrix = cosine_similarity(
        research_centroids,
        review_centroids
    )

    # Identify gaps
    gaps = {}
    for i, research_cluster in enumerate(research_clusters):
        max_similarity = np.max(similarity_matrix[i])

        if max_similarity < threshold:
            # This research cluster is underreviewed
            gaps[research_cluster] = {
                'coverage': max_similarity,
                'article_count': len(research_clusters[research_cluster]),
                'top_terms': extract_top_terms(research_cluster),
                'representative_articles': get_representative_articles(
                    research_cluster, n=3
                )
            }

    return gaps
```

#### Coverage Heatmap

```python
import plotly.express as px

def plot_coverage_heatmap(similarity_matrix, review_labels, research_labels):
    """
    Visualize coverage of research topics by reviews
    """
    fig = px.imshow(
        similarity_matrix,
        x=review_labels,
        y=research_labels,
        color_continuous_scale='RdYlGn',
        aspect='auto',
        labels={'x': 'Review Topics', 'y': 'Research Topics', 'color': 'Coverage'}
    )

    fig.update_layout(
        title='Research Coverage by Review Papers',
        xaxis_title='Review Clusters',
        yaxis_title='Research Clusters'
    )

    return fig
```

### 6. Interactive 3D Visualizations

Explore document clusters in three dimensions:

```python
import plotly.graph_objects as go

def create_3d_scatter(reduced_vectors, cluster_labels, titles):
    """
    Create interactive 3D scatter plot
    """
    fig = go.Figure()

    for cluster_id in np.unique(cluster_labels):
        mask = cluster_labels == cluster_id
        fig.add_trace(go.Scatter3d(
            x=reduced_vectors[mask, 0],
            y=reduced_vectors[mask, 1],
            z=reduced_vectors[mask, 2],
            mode='markers',
            name=f'Cluster {cluster_id}',
            text=[titles[i] for i in np.where(mask)[0]],
            hovertemplate='<b>%{text}</b><br>' +
                         'X: %{x:.2f}<br>' +
                         'Y: %{y:.2f}<br>' +
                         'Z: %{z:.2f}<extra></extra>',
            marker=dict(size=5, opacity=0.7)
        ))

    fig.update_layout(
        title='Literature Clustering (3D)',
        scene=dict(
            xaxis_title='Dimension 1',
            yaxis_title='Dimension 2',
            zaxis_title='Dimension 3'
        ),
        height=700
    )

    return fig
```

### 7. Extractive Summarization

Automatically generates cluster summaries:

```python
def summarize_cluster(cluster_documents, n_terms=10):
    """
    Extract key terms representing cluster theme

    Uses TF-IDF to identify most discriminative terms
    """
    # Calculate TF-IDF for cluster documents
    tfidf = TfidfVectorizer(max_features=100, stop_words='english')
    tfidf_matrix = tfidf.fit_transform(cluster_documents)

    # Get feature names and scores
    feature_names = tfidf.get_feature_names_out()
    scores = np.asarray(tfidf_matrix.sum(axis=0)).flatten()

    # Sort by score
    top_indices = np.argsort(scores)[::-1][:n_terms]
    top_terms = [feature_names[i] for i in top_indices]

    return top_terms
```

---

## System Architecture

```
┌──────────────────────────────────────────────┐
│           Streamlit Web Interface            │
│  (User Input, Visualization, Export)         │
└────────────────┬─────────────────────────────┘
                 │
                 ↓
┌──────────────────────────────────────────────┐
│         PubMed Scraper Module                │
│  • NCBI Entrez API Integration               │
│  • Query Construction                        │
│  • Metadata Extraction                       │
└────────────────┬─────────────────────────────┘
                 │
                 ↓
┌──────────────────────────────────────────────┐
│       Enhanced Clusterer Engine              │
├──────────────────────────────────────────────┤
│  Embedding Layer:                            │
│  • TF-IDF Vectorizer                         │
│  • Doc2Vec Model                             │
│  • FastText Model                            │
│                                              │
│  Clustering Layer:                           │
│  • K-Means                                   │
│  • DBSCAN                                    │
│  • Hierarchical                              │
│  • LDA                                       │
│                                              │
│  Reduction Layer:                            │
│  • PCA                                       │
│  • t-SNE                                     │
│  • UMAP                                      │
└────────────────┬─────────────────────────────┘
                 │
                 ↓
┌──────────────────────────────────────────────┐
│      Review Comparator Module                │
│  • Cluster Centroid Computation              │
│  • Cosine Similarity Matrix                  │
│  • Gap Threshold Analysis                    │
│  • Coverage Metrics                          │
└────────────────┬─────────────────────────────┘
                 │
                 ↓
┌──────────────────────────────────────────────┐
│      Visualization & Export                  │
│  • Plotly Interactive Plots                  │
│  • CSV Download                              │
│  • Gap Reports                               │
└──────────────────────────────────────────────┘
```

---

## Technical Stack

| Component | Technology | Purpose |
|-----------|-----------|---------|
| Web Framework | Streamlit | Interactive application |
| Database Access | Biopython (Entrez) | PubMed API integration |
| NLP Embeddings | Gensim (Doc2Vec, FastText) | Document representations |
| Text Vectorization | scikit-learn (TF-IDF) | Traditional embeddings |
| Clustering | scikit-learn | Unsupervised learning |
| Dimensionality Reduction | UMAP, t-SNE, PCA | Visualization |
| Visualization | Plotly | Interactive 3D plots |
| Data Manipulation | Pandas, NumPy | Data processing |

---

## Use Cases

### 1. Precision Nutrition Research

**Query:**
```
("genetics" OR "GWAS" OR "genomic") AND ("nutrition" OR "diet" OR "metabolism")
```

**Workflow:**
1. Scrape 500 articles from last 5 years
2. Separate reviews (n=50) from research (n=450)
3. Cluster research into 8 topics
4. Cluster reviews into 4 topics
5. Identify gaps: research clusters not covered by reviews

**Result:** Discovered underreviewed area in "nutrigenomics of microbiome interactions"

### 2. Exercise Physiology

**Query:**
```
("genes" OR "genetics") AND ("exercise" OR "physical activity" OR "training")
```

**Analysis:**
- K-Means clustering reveals 6 main themes
- LDA topic modeling identifies "exercise genetics" vs "training adaptation"
- Gap analysis shows need for reviews on "epigenetic exercise responses"

### 3. Clinical Medicine

**Query:**
```
("diabetes" OR "obesity") AND ("treatment" OR "intervention") AND ("randomized controlled trial"[PT])
```

**Insights:**
- Hierarchical clustering shows treatment taxonomy
- DBSCAN identifies outlier studies (novel interventions)
- Coverage heatmap highlights gaps in "combination therapy reviews"

---

## Installation & Usage

### Installation

```bash
# Clone repository
git clone https://github.com/lonespear/medrev.git
cd medrev

# Install dependencies
pip install -r requirements.txt
```

**Requirements:**
```
streamlit>=1.20.0
biopython>=1.79
scikit-learn>=1.0.0
gensim>=4.0.0
umap-learn>=0.5.0
plotly>=5.0.0
pandas>=1.3.0
numpy>=1.20.0
```

### Running Locally

```bash
streamlit run app_enhanced.py
```

### Access Live Demo

Visit: [https://medreview.streamlit.app/](https://medreview.streamlit.app/)

### Programmatic Usage

```python
from clustering_enhanced import EnhancedClusterer, ReviewComparator

# Load your article data
articles_df = pd.read_csv('pubmed_articles.csv')

# Initialize clusterer
clusterer = EnhancedClusterer(
    embedding_method='doc2vec',
    clustering_method='kmeans',
    n_clusters=8,
    reduction_method='umap'
)

# Fit and transform
results = clusterer.fit_transform(
    documents=articles_df['abstract'].tolist(),
    titles=articles_df['title'].tolist()
)

# Identify gaps
comparator = ReviewComparator()
gaps = comparator.find_gaps(
    review_articles=review_df,
    research_articles=research_df,
    threshold=0.3
)

# Visualize
fig = clusterer.plot_3d_clusters()
fig.show()

# Export
results_df = clusterer.export_results()
results_df.to_csv('cluster_results.csv')
```

---

## Performance Metrics

### Processing Speed

| Corpus Size | Embedding | Clustering | Total Time |
|-------------|-----------|------------|------------|
| 100 articles | 5s | 1s | ~6s |
| 500 articles | 20s | 3s | ~25s |
| 1,000 articles | 45s | 8s | ~55s |
| 5,000 articles | 4min | 40s | ~5min |
| 10,000 articles | 8min | 2min | ~10min |

*Tested on Intel i7-9700K, 32GB RAM*

### Memory Usage

- **TF-IDF**: ~50MB for 1,000 articles
- **Doc2Vec**: ~200MB for 1,000 articles
- **FastText**: ~500MB for 1,000 articles

### Clustering Quality (Silhouette Score)

| Method | Avg Score | Best Use Case |
|--------|-----------|---------------|
| K-Means | 0.45 | Well-separated topics |
| DBSCAN | 0.38 | Irregular clusters |
| Hierarchical | 0.42 | Nested topics |
| LDA | 0.40 | Topic modeling |

---

## Research Paper

**Title:** Literature Reviews in the Age of Precision Nutrition

**Authors:**
- Jake R. Beckman
- Jon Day
- Russell Nelson
- Quinten Weeks
- Joseph Dorta
- Moussa Doumbia
- Diana M. Thomas

**Institution:** Department of Mathematical Sciences, United States Military Academy, West Point, NY

**Funding:**
- Nutrition for Precision Health (NPH) Initiative
- All of Us Research Program
- NIH Common Fund

**Abstract:**
This paper introduces MedScrape, a novel platform for automated literature review and research gap identification. We demonstrate its effectiveness in the domain of precision nutrition, showing how unsupervised learning can systematically identify underreviewed research areas. Our methodology combines PubMed scraping, multiple clustering algorithms, and cosine similarity-based gap detection to provide researchers with actionable insights for future review articles.

**Contact:** Dr. Diana Thomas (diana.thomas@westpoint.edu)

---

## Future Enhancements

### Planned Features

1. **Additional Databases**
   - Web of Science integration
   - Scopus support
   - arXiv for preprints
   - bioRxiv for biology

2. **Advanced Analytics**
   - Citation network analysis
   - Author collaboration networks
   - Temporal trend analysis
   - Journal impact metrics

3. **Automation**
   - API endpoints for programmatic access
   - Scheduled searches with email alerts
   - Automated gap report generation
   - Integration with reference managers (Zotero, Mendeley)

4. **Enhanced NLP**
   - Transformer-based embeddings (BERT, SciBERT)
   - Named entity recognition
   - Relationship extraction
   - Multi-language support

5. **Collaboration Features**
   - User accounts and saved searches
   - Shared project workspaces
   - Annotation and tagging
   - Team collaboration tools

---

## Contributing

We welcome contributions! Priority areas:

- **Performance Optimization**: Speed up embedding generation
- **New Algorithms**: Additional clustering methods
- **Database Integration**: Support for more literature databases
- **Visualization**: Enhanced plotting options
- **Documentation**: Usage examples and tutorials
- **Testing**: Unit tests and integration tests

---

## Citation

If you use MedScrape in your research, please cite:

```
Beckman, J. R., Day, J., Nelson, R., Weeks, Q., Dorta, J., Doumbia, M., & Thomas, D. M. (2024).
Literature Reviews in the Age of Precision Nutrition.
Department of Mathematical Sciences, United States Military Academy, West Point, NY.
```

**BibTeX:**
```bibtex
@software{medreview2024,
  author = {Beckman, Jake R. and Day, Jonathan and Nelson, Russell and
            Weeks, Quinten and Dorta, Joseph and Doumbia, Moussa and Thomas, Diana M.},
  title = {MedScrape: AI-Powered Literature Review Platform},
  year = {2024},
  publisher = {GitHub},
  url = {https://github.com/lonespear/medrev}
}
```

---

## License

This project is supported by the Nutrition for Precision Health Initiative and the All of Us Research Program.

---

## Contact & Support

**Development Team:**
Department of Mathematical Sciences
United States Military Academy
West Point, NY 10996

**Principal Investigator:**
Dr. Diana M. Thomas
Email: diana.thomas@westpoint.edu

**Developer:**
CPT Jonathan Day
Email: jonathan.day@westpoint.edu

**Repository Issues:** [GitHub Issues](https://github.com/lonespear/medrev/issues)

---

[← Back to Projects](index.qmd){.btn .btn-secondary}
[View on GitHub](https://github.com/lonespear/medrev){.btn .btn-primary target="_blank"}
[Try Live Demo](https://medreview.streamlit.app/){.btn .btn-success target="_blank"}
